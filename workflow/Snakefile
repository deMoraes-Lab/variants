configfile: "config/config.yaml"


from snakemake.utils import available_cpu_count
from pathlib import Path

# RefSeq ID of reference genome
ID = config["reference_id"]
assert ID is not None, "Please provide a NCBI accession for reference genome."

# Paths to input files
INPUT = config["input"]
assert Path(INPUT).exists(), "Please provide an input file."


def parse_input(ptsv):
    import csv

    with open(ptsv, "r") as ftsv:
        names = list()
        forwards = list()
        reverses = list()
        for row in csv.reader(ftsv, delimiter="\t"):
            name, forward, reverse = row
            names.append(name)
            forwards.append(forward)
            reverses.append(reverse)
    return names, forwards, reverses


NAMES, FORWARDS, REVERSES = parse_input(INPUT)


def apply(l, f):
    return [f(i) for i in l]


assert (
    len(NAMES) == len(FORWARDS) == len(REVERSES)
), "input.tsv error, columns of different length."
f = lambda x: x != "" and isinstance(x, str)
assert (
    all(apply(NAMES, f)) and all(apply(FORWARDS, f)) and all(apply(REVERSES, f))
), "Empty string on input data."

f = lambda x: Path(x).exists()
assert all(apply(FORWARDS, f)), "Forward file not found."
assert all(apply(REVERSES, f)), "Reverse file not found."

RESULTS_DIR = config["results"]
RESULTS_DIR_ALIGN = f"{RESULTS_DIR}/alignments"
RESULTS_DIR_REFERENCE = f"{RESULTS_DIR}/reference"


PVAL = config["pval"]
FREQ = config["freq"]


ALL = expand("{results}/{names}.varscan.tsv", results=RESULTS_DIR, names=NAMES)


rule all:
    input:
        ALL,


rule download_reference:
    output:
        zip=f"{RESULTS_DIR_REFERENCE}/{ID}.zip",
    conda:
        "envs/ncbi_datasets.yaml"
    shell:
        """
        datasets download genome accession {ID} --filename {output.zip} --include genome
        """


rule unzip_reference:
    input:
        zip=rules.download_reference.output.zip,
    output:
        fna=f"{RESULTS_DIR_REFERENCE}/{ID}.fna",
    shell:
        """
        unzip -o {input} -d {RESULTS_DIR_REFERENCE}

        # Flatten ncbi dir structure
        mv {RESULTS_DIR_REFERENCE}/ncbi_dataset/data/{ID}/* \
           {RESULTS_DIR_REFERENCE}

        # Rename fna
        mv {RESULTS_DIR_REFERENCE}/*.fna {output}

        # Remove crust
        rm -r {RESULTS_DIR_REFERENCE}/ncbi_dataset/ \
              {RESULTS_DIR_REFERENCE}/README.md
        """


rule index_reference:
    input:
        fna=rules.unzip_reference.output.fna,
    output:
        indexes=multiext(
            f"{RESULTS_DIR_REFERENCE}/{ID}",
            ".1.bt2",
            ".2.bt2",
            ".3.bt2",
            ".4.bt2",
            ".rev.1.bt2",
            ".rev.2.bt2",
        ),
    params:
        indexes_basename=f"{RESULTS_DIR_REFERENCE}/{ID}",
    threads: workflow.cores
    conda:
        "envs/bowtie2.yaml"
    shell:
        """
        bowtie2-build --threads {threads} {input.fna} {params.indexes_basename}
        """


rule align:
    input:
        fq_forward=lambda w: FORWARDS[NAMES.index(w.name)],
        fq_reverse=lambda w: REVERSES[NAMES.index(w.name)],
        indexes=rules.index_reference.output.indexes,
    output:
        sam=f"{RESULTS_DIR_ALIGN}/{{name}}.sam",
    params:
        indexes_basename=f"{RESULTS_DIR_REFERENCE}/{ID}",
    threads: workflow.cores
    conda:
        "envs/bowtie2.yaml"
    shell:
        """
        bowtie2 -p {threads} -x {params.indexes_basename} -1 {input.fq_forward} -2 {input.fq_reverse} -S {output.sam}
        """


rule get_bam:
    input:
        sam=rules.align.output.sam,
    output:
        bam=f"{RESULTS_DIR_ALIGN}/{{name}}.bam",
    conda:
        "envs/samtools.yaml"
    shell:
        """
        samtools view -S -b {input.sam} >| {output.bam}
        """


rule sort_bam:
    input:
        bam=rules.get_bam.output.bam,
    output:
        sbam=f"{RESULTS_DIR_ALIGN}/{{name}}.sorted.bam",
    conda:
        "envs/samtools.yaml"
    shell:
        """
        samtools sort {input.bam} -o {output.sbam}
        """


rule index_bam:
    input:
        sbam=rules.sort_bam.output.sbam,
    output:
        bai=f"{RESULTS_DIR_ALIGN}/{{name}}.sorted.bam.bai",
    conda:
        "envs/samtools.yaml"
    shell:
        """
        samtools index {input.sbam} -o {output.bai}
        """


rule get_mpileup:
    input:
        fna=rules.unzip_reference.output.fna,
        sbam=rules.sort_bam.output.sbam,
    output:
        mpileup=f"{RESULTS_DIR_ALIGN}/{{name}}.mpileup",
    conda:
        "envs/samtools.yaml"
    shell:
        """
        samtools mpileup -f {input.fna} {input.sbam} -o {output.mpileup}
        """


rule call_variants:
    input:
        mpileup=rules.get_mpileup.output.mpileup,
    output:
        tsv=f"{RESULTS_DIR}/{{name}}.varscan.tsv",
    log:
        f"{RESULTS_DIR}/{{name}}.varscan.log",
    params:
        pval=PVAL,
        freq=FREQ,
    conda:
        "envs/varscan.yaml"
    shell:
        """
        varscan pileup2snp {input.mpileup} --min-var-freq {params.freq} --p-value {params.pval} >| {output.tsv} 2>| {log}
        """
